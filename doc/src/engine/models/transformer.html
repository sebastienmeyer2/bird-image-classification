<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>src.engine.models.transformer API documentation</title>
<meta name="description" content="Wrapper for Transformer models." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.engine.models.transformer</code></h1>
</header>
<section id="section-intro">
<p>Wrapper for Transformer models.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Wrapper for Transformer models.&#34;&#34;&#34;


from functools import partial

from typing import Any, Dict, Union

import numpy as np

import torch
from torch.nn import CrossEntropyLoss
from torch.optim import SGD, RMSprop, Adam
from torch.utils.data import DataLoader
from torchvision.transforms import (
    ColorJitter, Compose, InterpolationMode, Normalize, RandomHorizontalFlip, RandomResizedCrop,
    RandomRotation, ToTensor
)

from datasets.dataset_dict import DatasetDict
from transformers import AutoModelForImageClassification, get_scheduler, AutoFeatureExtractor


from utils.data_preparation import apply_transform, collate_fn


class TransformerEstimator():
    &#34;&#34;&#34;Transfer learning of Google ViT.&#34;&#34;&#34;

    def __init__(self, model_name: str, params: Dict[str, Any], n_classes: int = 20):
        &#34;&#34;&#34;Initialize the model.

        Parameters
        ----------
        model_name : str
            The name of model following project usage. See README.md for more information. Only
            present for compatibility.

        params : dict of {str: any}
            A dictionary of parameters for chosen **model_name**. It contains all parameters to
            initialize and fit the model.

        n_classes : int, default=20
            Number of classes.
        &#34;&#34;&#34;
        self.model_name = model_name

        # Model parameters
        self.model_params = params

        # Base architecture
        self.model_checkpoint = &#34;google/vit-base-patch16-224&#34;

        self.feature_extractor = AutoFeatureExtractor.from_pretrained(self.model_checkpoint)
        self.model = AutoModelForImageClassification.from_pretrained(
            self.model_checkpoint, num_labels=n_classes, ignore_mismatched_sizes=True
        )

        # Move to CUDA
        self.model.cuda()

    def fit(self, dataset: DatasetDict) -&gt; float:
        &#34;&#34;&#34;Wrapper of fit method.

        Parameters
        ----------
        dataset : `DatasetDict`
            A dictionary containing training and validation sets.

        Returns
        -------
        best_val_acc : float
            Best obtained validation accuracy for all epochs until early stopping or end.
        &#34;&#34;&#34;
        # Get parameters
        batch_size = self.model_params.get(&#34;batch_size&#34;, 12)
        epochs = self.model_params.get(&#34;epochs&#34;, 20)
        verbose = self.model_params.get(&#34;verbose&#34;, 1)
        patience = self.model_params.get(&#34;patience&#34;, 2)

        # Apply transforms on the fly
        transforms = self.create_transform()

        dataset.set_transform(partial(apply_transform, transforms))

        train_set = dataset[&#34;train&#34;]
        val_set = dataset[&#34;validation&#34;]

        # Load dataset
        train_loader = DataLoader(
            train_set, batch_size=batch_size, collate_fn=collate_fn, shuffle=True, num_workers=1
        )
        val_loader = DataLoader(
            val_set, batch_size=batch_size, collate_fn=collate_fn, shuffle=False, num_workers=1
        )

        n_train = len(train_loader.dataset)
        n_train_batches = len(train_loader)

        n_val = len(val_loader.dataset)
        n_val_batches = len(val_loader)

        # Initialize optimizer and learning rate scheduler
        optimizer = self.create_optimizer()

        n_train_steps = epochs * n_train_batches
        lr_scheduler = get_scheduler(
            name=&#34;linear&#34;, optimizer=optimizer, num_warmup_steps=0,
            num_training_steps=n_train_steps
        )

        # Start training
        use_cuda = True
        log_interval = 1

        val_loss_list = []
        val_acc_list = []

        for epoch in range(epochs):

            # Training
            self.model.train()

            train_loss = 0
            train_correct = 0

            for batch_idx, batch in enumerate(train_loader):

                if use_cuda:
                    batch = {k: v.cuda() for k, v in batch.items()}

                data = batch[&#34;pixel_values&#34;]
                target = batch[&#34;labels&#34;]

                # Set optimizer to zero grad
                optimizer.zero_grad()

                # Forward pass
                output = self.model(**batch).logits

                criterion = CrossEntropyLoss(reduction=&#34;mean&#34;)
                loss = criterion(output, target)

                # Backward pass
                loss.backward()

                optimizer.step()
                lr_scheduler.step()

                # Compute metrics and eventually print
                if verbose &gt; 0 and batch_idx % log_interval == 0:

                    n_cur = batch_idx * len(data)
                    perc_cur = 100. * batch_idx / n_train_batches
                    log_msg = f&#34;[{n_cur}/{n_train} ({perc_cur:.0f}%)]&#34;

                    batch_loss = loss.data.item()
                    log_msg += f&#34;\tBatch loss: {batch_loss:.3f}&#34;

                    pred = output.data.max(1, keepdim=True)[1]
                    correct = pred.eq(target.data.view_as(pred)).cpu().sum()
                    batch_acc = 100. * correct / len(data)
                    log_msg += f&#34;\tBatch acc: {batch_acc:.2f}&#34;

                    print(log_msg)

                    train_loss += batch_loss  # total loss for epoch
                    train_correct += correct  # total number of correct predictions for epoch

            train_loss /= n_train_batches
            train_acc = 100. * train_correct / n_train

            log_msg = f&#34;\nEpoch {epoch}; Training set: &#34;
            log_msg += f&#34;Average loss: {train_loss:.4f}; &#34;
            log_msg += f&#34;Accuracy: {train_correct}/{n_train} ({train_acc:.2f}%)&#34;
            print(log_msg)

            # Validation
            self.model.eval()

            val_loss = 0
            val_correct = 0

            for batch in val_loader:

                if use_cuda:
                    batch = {k: v.cuda() for k, v in batch.items()}

                data = batch[&#34;pixel_values&#34;]
                target = batch[&#34;labels&#34;]

                # Forward pass
                output = self.model(**batch).logits

                criterion = CrossEntropyLoss(reduction=&#34;mean&#34;)
                val_loss += criterion(output, target).data.item()

                pred = output.data.max(1, keepdim=True)[1]
                val_correct += pred.eq(target.data.view_as(pred)).cpu().sum()

            val_loss /= n_val_batches
            val_acc = 100. * val_correct / n_val

            log_msg = &#34;Validation set: &#34;
            log_msg += f&#34;Average loss: {val_loss:.4f}; &#34;
            log_msg += f&#34;Accuracy: {val_correct}/{n_val} ({val_acc:.2f}%)\n&#34;
            print(log_msg)

            val_loss_list.append(val_loss)
            val_acc_list.append(val_acc)

            # Early stopping
            if len(val_acc_list) &gt; patience:

                worse_acc = True
                for past_acc in val_acc_list[-1-patience:-1]:
                    if val_acc_list[-1] &gt; past_acc:
                        worse_acc = False

                if worse_acc:

                    log_msg = &#34;Early stopping - patience&#34;
                    print(log_msg)

                    best_val_acc = np.max(val_acc_list)

                    return best_val_acc

            if val_acc &lt; 10:

                log_msg = &#34;Early stopping - very bad model&#34;
                print(log_msg)

                best_val_acc = np.max(val_acc_list)

                return best_val_acc

        model_file = f&#34;experiment/{self.model_name}_{str(epoch)}.pth&#34;
        torch.save(self.model.state_dict(), model_file)

        log_msg = f&#34;Saved model to {model_file}\n&#34;
        print(log_msg)

        best_val_acc = np.max(val_acc_list)

        return best_val_acc

    def create_optimizer(self) -&gt; Union[SGD, RMSprop, Adam]:
        &#34;&#34;&#34;Build up an optimizer.

        Parameters
        ----------
        params : dict of {str: any}
            A dictionary of parameters for the model. It contains all parameters to initialize and
            fit the model.

        Returns
        -------
        optimizer : `SGD`, `Adam` or `RMSProp`
            Initialized optimizer.

        Raises
        ------
        ValueError
            If the optimizer is not supported.
        &#34;&#34;&#34;
        optim_name = self.model_params.get(&#34;optim_name&#34;, &#34;sgd&#34;)

        if optim_name == &#34;sgd&#34;:

            learning_rate = self.model_params.get(&#34;learning_rate&#34;, 0.000668)
            momentum = self.model_params.get(&#34;momentum&#34;, 0.629)

            optimizer = SGD(self.model.parameters(), lr=learning_rate, momentum=momentum)

        elif optim_name == &#34;rmsprop&#34;:

            learning_rate = self.model_params.get(&#34;learning_rate&#34;, 0.01)
            alpha = self.model_params.get(&#34;alpha&#34;, 0.99)
            momentum = self.model_params.get(&#34;momentum&#34;, 0.)

            optimizer = RMSprop(
                self.model.parameters(), lr=learning_rate, alpha=alpha, momentum=momentum
            )

        elif optim_name == &#34;adam&#34;:

            learning_rate = self.model_params.get(&#34;learning_rate&#34;, 0.001)
            beta_1 = self.model_params.get(&#34;beta_1&#34;, 0.9)
            beta_2 = self.model_params.get(&#34;beta_2&#34;, 0.999)

            optimizer = Adam(self.model.parameters(), lr=learning_rate, betas=(beta_1, beta_2))

        else:

            err_msg = f&#34;Unknown optimizer {optim_name}.&#34;
            raise ValueError(err_msg)

        return optimizer

    def create_transform(self) -&gt; Compose:
        &#34;&#34;&#34;Initialize transform to apply to all images.

        Returns
        -------
        transform : torchvision.transforms.Compose
            A sequence of transformations to apply to input images.
        &#34;&#34;&#34;
        # Get parameters
        min_scale = self.model_params.get(&#34;min_scale&#34;, 0.523)
        max_scale = self.model_params.get(&#34;max_scale&#34;, 0.957)
        min_ratio = self.model_params.get(&#34;min_ratio&#34;, 0.704)
        max_ratio = self.model_params.get(&#34;max_ratio&#34;, 1.362)

        do_jitter = self.model_params.get(&#34;do_jitter&#34;, False)
        brightness = self.model_params.get(&#34;brightness&#34;, 0)
        contrast = self.model_params.get(&#34;contrast&#34;, 0)
        saturation = self.model_params.get(&#34;saturation&#34;, 0)
        hue = self.model_params.get(&#34;hue&#34;, 0)

        do_rotation = self.model_params.get(&#34;do_rotation&#34;, False)
        degrees = self.model_params.get(&#34;degrees&#34;, 10)

        do_hflip = self.model_params.get(&#34;do_hflip&#34;, False)
        p = self.model_params.get(&#34;p&#34;, 0.55)

        # List of transforms to apply
        transform_list = []

        if self.feature_extractor.do_resize:
            transform_list.append(
                RandomResizedCrop(
                    (self.feature_extractor.size, self.feature_extractor.size),
                    scale=(min_scale, max_scale), ratio=(min_ratio, max_ratio)
                )
            )

        if do_jitter:
            transform_list.append(
                ColorJitter(
                    brightness=brightness, contrast=contrast, saturation=saturation, hue=hue
                )
            )

        if do_rotation:
            transform_list.append(RandomRotation(degrees, interpolation=InterpolationMode.BILINEAR))

        if do_hflip:
            transform_list.append(RandomHorizontalFlip(p=p))

        transform_list.append(ToTensor())

        if self.feature_extractor.do_normalize:
            transform_list.append(
                Normalize(
                    mean=self.feature_extractor.image_mean, std=self.feature_extractor.image_std
                )
            )

        transform = Compose(transform_list)

        return transform</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="src.engine.models.transformer.TransformerEstimator"><code class="flex name class">
<span>class <span class="ident">TransformerEstimator</span></span>
<span>(</span><span>model_name: str, params: Dict[str, Any], n_classes: int = 20)</span>
</code></dt>
<dd>
<div class="desc"><p>Transfer learning of Google ViT.</p>
<p>Initialize the model.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of model following project usage. See README.md for more information. Only
present for compatibility.</dd>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code> of <code>{str: any}</code></dt>
<dd>A dictionary of parameters for chosen <strong>model_name</strong>. It contains all parameters to
initialize and fit the model.</dd>
<dt><strong><code>n_classes</code></strong> :&ensp;<code>int</code>, default=<code>20</code></dt>
<dd>Number of classes.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TransformerEstimator():
    &#34;&#34;&#34;Transfer learning of Google ViT.&#34;&#34;&#34;

    def __init__(self, model_name: str, params: Dict[str, Any], n_classes: int = 20):
        &#34;&#34;&#34;Initialize the model.

        Parameters
        ----------
        model_name : str
            The name of model following project usage. See README.md for more information. Only
            present for compatibility.

        params : dict of {str: any}
            A dictionary of parameters for chosen **model_name**. It contains all parameters to
            initialize and fit the model.

        n_classes : int, default=20
            Number of classes.
        &#34;&#34;&#34;
        self.model_name = model_name

        # Model parameters
        self.model_params = params

        # Base architecture
        self.model_checkpoint = &#34;google/vit-base-patch16-224&#34;

        self.feature_extractor = AutoFeatureExtractor.from_pretrained(self.model_checkpoint)
        self.model = AutoModelForImageClassification.from_pretrained(
            self.model_checkpoint, num_labels=n_classes, ignore_mismatched_sizes=True
        )

        # Move to CUDA
        self.model.cuda()

    def fit(self, dataset: DatasetDict) -&gt; float:
        &#34;&#34;&#34;Wrapper of fit method.

        Parameters
        ----------
        dataset : `DatasetDict`
            A dictionary containing training and validation sets.

        Returns
        -------
        best_val_acc : float
            Best obtained validation accuracy for all epochs until early stopping or end.
        &#34;&#34;&#34;
        # Get parameters
        batch_size = self.model_params.get(&#34;batch_size&#34;, 12)
        epochs = self.model_params.get(&#34;epochs&#34;, 20)
        verbose = self.model_params.get(&#34;verbose&#34;, 1)
        patience = self.model_params.get(&#34;patience&#34;, 2)

        # Apply transforms on the fly
        transforms = self.create_transform()

        dataset.set_transform(partial(apply_transform, transforms))

        train_set = dataset[&#34;train&#34;]
        val_set = dataset[&#34;validation&#34;]

        # Load dataset
        train_loader = DataLoader(
            train_set, batch_size=batch_size, collate_fn=collate_fn, shuffle=True, num_workers=1
        )
        val_loader = DataLoader(
            val_set, batch_size=batch_size, collate_fn=collate_fn, shuffle=False, num_workers=1
        )

        n_train = len(train_loader.dataset)
        n_train_batches = len(train_loader)

        n_val = len(val_loader.dataset)
        n_val_batches = len(val_loader)

        # Initialize optimizer and learning rate scheduler
        optimizer = self.create_optimizer()

        n_train_steps = epochs * n_train_batches
        lr_scheduler = get_scheduler(
            name=&#34;linear&#34;, optimizer=optimizer, num_warmup_steps=0,
            num_training_steps=n_train_steps
        )

        # Start training
        use_cuda = True
        log_interval = 1

        val_loss_list = []
        val_acc_list = []

        for epoch in range(epochs):

            # Training
            self.model.train()

            train_loss = 0
            train_correct = 0

            for batch_idx, batch in enumerate(train_loader):

                if use_cuda:
                    batch = {k: v.cuda() for k, v in batch.items()}

                data = batch[&#34;pixel_values&#34;]
                target = batch[&#34;labels&#34;]

                # Set optimizer to zero grad
                optimizer.zero_grad()

                # Forward pass
                output = self.model(**batch).logits

                criterion = CrossEntropyLoss(reduction=&#34;mean&#34;)
                loss = criterion(output, target)

                # Backward pass
                loss.backward()

                optimizer.step()
                lr_scheduler.step()

                # Compute metrics and eventually print
                if verbose &gt; 0 and batch_idx % log_interval == 0:

                    n_cur = batch_idx * len(data)
                    perc_cur = 100. * batch_idx / n_train_batches
                    log_msg = f&#34;[{n_cur}/{n_train} ({perc_cur:.0f}%)]&#34;

                    batch_loss = loss.data.item()
                    log_msg += f&#34;\tBatch loss: {batch_loss:.3f}&#34;

                    pred = output.data.max(1, keepdim=True)[1]
                    correct = pred.eq(target.data.view_as(pred)).cpu().sum()
                    batch_acc = 100. * correct / len(data)
                    log_msg += f&#34;\tBatch acc: {batch_acc:.2f}&#34;

                    print(log_msg)

                    train_loss += batch_loss  # total loss for epoch
                    train_correct += correct  # total number of correct predictions for epoch

            train_loss /= n_train_batches
            train_acc = 100. * train_correct / n_train

            log_msg = f&#34;\nEpoch {epoch}; Training set: &#34;
            log_msg += f&#34;Average loss: {train_loss:.4f}; &#34;
            log_msg += f&#34;Accuracy: {train_correct}/{n_train} ({train_acc:.2f}%)&#34;
            print(log_msg)

            # Validation
            self.model.eval()

            val_loss = 0
            val_correct = 0

            for batch in val_loader:

                if use_cuda:
                    batch = {k: v.cuda() for k, v in batch.items()}

                data = batch[&#34;pixel_values&#34;]
                target = batch[&#34;labels&#34;]

                # Forward pass
                output = self.model(**batch).logits

                criterion = CrossEntropyLoss(reduction=&#34;mean&#34;)
                val_loss += criterion(output, target).data.item()

                pred = output.data.max(1, keepdim=True)[1]
                val_correct += pred.eq(target.data.view_as(pred)).cpu().sum()

            val_loss /= n_val_batches
            val_acc = 100. * val_correct / n_val

            log_msg = &#34;Validation set: &#34;
            log_msg += f&#34;Average loss: {val_loss:.4f}; &#34;
            log_msg += f&#34;Accuracy: {val_correct}/{n_val} ({val_acc:.2f}%)\n&#34;
            print(log_msg)

            val_loss_list.append(val_loss)
            val_acc_list.append(val_acc)

            # Early stopping
            if len(val_acc_list) &gt; patience:

                worse_acc = True
                for past_acc in val_acc_list[-1-patience:-1]:
                    if val_acc_list[-1] &gt; past_acc:
                        worse_acc = False

                if worse_acc:

                    log_msg = &#34;Early stopping - patience&#34;
                    print(log_msg)

                    best_val_acc = np.max(val_acc_list)

                    return best_val_acc

            if val_acc &lt; 10:

                log_msg = &#34;Early stopping - very bad model&#34;
                print(log_msg)

                best_val_acc = np.max(val_acc_list)

                return best_val_acc

        model_file = f&#34;experiment/{self.model_name}_{str(epoch)}.pth&#34;
        torch.save(self.model.state_dict(), model_file)

        log_msg = f&#34;Saved model to {model_file}\n&#34;
        print(log_msg)

        best_val_acc = np.max(val_acc_list)

        return best_val_acc

    def create_optimizer(self) -&gt; Union[SGD, RMSprop, Adam]:
        &#34;&#34;&#34;Build up an optimizer.

        Parameters
        ----------
        params : dict of {str: any}
            A dictionary of parameters for the model. It contains all parameters to initialize and
            fit the model.

        Returns
        -------
        optimizer : `SGD`, `Adam` or `RMSProp`
            Initialized optimizer.

        Raises
        ------
        ValueError
            If the optimizer is not supported.
        &#34;&#34;&#34;
        optim_name = self.model_params.get(&#34;optim_name&#34;, &#34;sgd&#34;)

        if optim_name == &#34;sgd&#34;:

            learning_rate = self.model_params.get(&#34;learning_rate&#34;, 0.000668)
            momentum = self.model_params.get(&#34;momentum&#34;, 0.629)

            optimizer = SGD(self.model.parameters(), lr=learning_rate, momentum=momentum)

        elif optim_name == &#34;rmsprop&#34;:

            learning_rate = self.model_params.get(&#34;learning_rate&#34;, 0.01)
            alpha = self.model_params.get(&#34;alpha&#34;, 0.99)
            momentum = self.model_params.get(&#34;momentum&#34;, 0.)

            optimizer = RMSprop(
                self.model.parameters(), lr=learning_rate, alpha=alpha, momentum=momentum
            )

        elif optim_name == &#34;adam&#34;:

            learning_rate = self.model_params.get(&#34;learning_rate&#34;, 0.001)
            beta_1 = self.model_params.get(&#34;beta_1&#34;, 0.9)
            beta_2 = self.model_params.get(&#34;beta_2&#34;, 0.999)

            optimizer = Adam(self.model.parameters(), lr=learning_rate, betas=(beta_1, beta_2))

        else:

            err_msg = f&#34;Unknown optimizer {optim_name}.&#34;
            raise ValueError(err_msg)

        return optimizer

    def create_transform(self) -&gt; Compose:
        &#34;&#34;&#34;Initialize transform to apply to all images.

        Returns
        -------
        transform : torchvision.transforms.Compose
            A sequence of transformations to apply to input images.
        &#34;&#34;&#34;
        # Get parameters
        min_scale = self.model_params.get(&#34;min_scale&#34;, 0.523)
        max_scale = self.model_params.get(&#34;max_scale&#34;, 0.957)
        min_ratio = self.model_params.get(&#34;min_ratio&#34;, 0.704)
        max_ratio = self.model_params.get(&#34;max_ratio&#34;, 1.362)

        do_jitter = self.model_params.get(&#34;do_jitter&#34;, False)
        brightness = self.model_params.get(&#34;brightness&#34;, 0)
        contrast = self.model_params.get(&#34;contrast&#34;, 0)
        saturation = self.model_params.get(&#34;saturation&#34;, 0)
        hue = self.model_params.get(&#34;hue&#34;, 0)

        do_rotation = self.model_params.get(&#34;do_rotation&#34;, False)
        degrees = self.model_params.get(&#34;degrees&#34;, 10)

        do_hflip = self.model_params.get(&#34;do_hflip&#34;, False)
        p = self.model_params.get(&#34;p&#34;, 0.55)

        # List of transforms to apply
        transform_list = []

        if self.feature_extractor.do_resize:
            transform_list.append(
                RandomResizedCrop(
                    (self.feature_extractor.size, self.feature_extractor.size),
                    scale=(min_scale, max_scale), ratio=(min_ratio, max_ratio)
                )
            )

        if do_jitter:
            transform_list.append(
                ColorJitter(
                    brightness=brightness, contrast=contrast, saturation=saturation, hue=hue
                )
            )

        if do_rotation:
            transform_list.append(RandomRotation(degrees, interpolation=InterpolationMode.BILINEAR))

        if do_hflip:
            transform_list.append(RandomHorizontalFlip(p=p))

        transform_list.append(ToTensor())

        if self.feature_extractor.do_normalize:
            transform_list.append(
                Normalize(
                    mean=self.feature_extractor.image_mean, std=self.feature_extractor.image_std
                )
            )

        transform = Compose(transform_list)

        return transform</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="src.engine.models.transformer.TransformerEstimator.create_optimizer"><code class="name flex">
<span>def <span class="ident">create_optimizer</span></span>(<span>self) ‑> Union[torch.optim.sgd.SGD, torch.optim.rmsprop.RMSprop, torch.optim.adam.Adam]</span>
</code></dt>
<dd>
<div class="desc"><p>Build up an optimizer.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code> of <code>{str: any}</code></dt>
<dd>A dictionary of parameters for the model. It contains all parameters to initialize and
fit the model.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>optimizer</code></strong> :&ensp;<code>SGD<code>,</code>Adam</code> or <code>RMSProp</code></dt>
<dd>Initialized optimizer.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the optimizer is not supported.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_optimizer(self) -&gt; Union[SGD, RMSprop, Adam]:
    &#34;&#34;&#34;Build up an optimizer.

    Parameters
    ----------
    params : dict of {str: any}
        A dictionary of parameters for the model. It contains all parameters to initialize and
        fit the model.

    Returns
    -------
    optimizer : `SGD`, `Adam` or `RMSProp`
        Initialized optimizer.

    Raises
    ------
    ValueError
        If the optimizer is not supported.
    &#34;&#34;&#34;
    optim_name = self.model_params.get(&#34;optim_name&#34;, &#34;sgd&#34;)

    if optim_name == &#34;sgd&#34;:

        learning_rate = self.model_params.get(&#34;learning_rate&#34;, 0.000668)
        momentum = self.model_params.get(&#34;momentum&#34;, 0.629)

        optimizer = SGD(self.model.parameters(), lr=learning_rate, momentum=momentum)

    elif optim_name == &#34;rmsprop&#34;:

        learning_rate = self.model_params.get(&#34;learning_rate&#34;, 0.01)
        alpha = self.model_params.get(&#34;alpha&#34;, 0.99)
        momentum = self.model_params.get(&#34;momentum&#34;, 0.)

        optimizer = RMSprop(
            self.model.parameters(), lr=learning_rate, alpha=alpha, momentum=momentum
        )

    elif optim_name == &#34;adam&#34;:

        learning_rate = self.model_params.get(&#34;learning_rate&#34;, 0.001)
        beta_1 = self.model_params.get(&#34;beta_1&#34;, 0.9)
        beta_2 = self.model_params.get(&#34;beta_2&#34;, 0.999)

        optimizer = Adam(self.model.parameters(), lr=learning_rate, betas=(beta_1, beta_2))

    else:

        err_msg = f&#34;Unknown optimizer {optim_name}.&#34;
        raise ValueError(err_msg)

    return optimizer</code></pre>
</details>
</dd>
<dt id="src.engine.models.transformer.TransformerEstimator.create_transform"><code class="name flex">
<span>def <span class="ident">create_transform</span></span>(<span>self) ‑> torchvision.transforms.transforms.Compose</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize transform to apply to all images.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>transform</code></strong> :&ensp;<code>torchvision.transforms.Compose</code></dt>
<dd>A sequence of transformations to apply to input images.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_transform(self) -&gt; Compose:
    &#34;&#34;&#34;Initialize transform to apply to all images.

    Returns
    -------
    transform : torchvision.transforms.Compose
        A sequence of transformations to apply to input images.
    &#34;&#34;&#34;
    # Get parameters
    min_scale = self.model_params.get(&#34;min_scale&#34;, 0.523)
    max_scale = self.model_params.get(&#34;max_scale&#34;, 0.957)
    min_ratio = self.model_params.get(&#34;min_ratio&#34;, 0.704)
    max_ratio = self.model_params.get(&#34;max_ratio&#34;, 1.362)

    do_jitter = self.model_params.get(&#34;do_jitter&#34;, False)
    brightness = self.model_params.get(&#34;brightness&#34;, 0)
    contrast = self.model_params.get(&#34;contrast&#34;, 0)
    saturation = self.model_params.get(&#34;saturation&#34;, 0)
    hue = self.model_params.get(&#34;hue&#34;, 0)

    do_rotation = self.model_params.get(&#34;do_rotation&#34;, False)
    degrees = self.model_params.get(&#34;degrees&#34;, 10)

    do_hflip = self.model_params.get(&#34;do_hflip&#34;, False)
    p = self.model_params.get(&#34;p&#34;, 0.55)

    # List of transforms to apply
    transform_list = []

    if self.feature_extractor.do_resize:
        transform_list.append(
            RandomResizedCrop(
                (self.feature_extractor.size, self.feature_extractor.size),
                scale=(min_scale, max_scale), ratio=(min_ratio, max_ratio)
            )
        )

    if do_jitter:
        transform_list.append(
            ColorJitter(
                brightness=brightness, contrast=contrast, saturation=saturation, hue=hue
            )
        )

    if do_rotation:
        transform_list.append(RandomRotation(degrees, interpolation=InterpolationMode.BILINEAR))

    if do_hflip:
        transform_list.append(RandomHorizontalFlip(p=p))

    transform_list.append(ToTensor())

    if self.feature_extractor.do_normalize:
        transform_list.append(
            Normalize(
                mean=self.feature_extractor.image_mean, std=self.feature_extractor.image_std
            )
        )

    transform = Compose(transform_list)

    return transform</code></pre>
</details>
</dd>
<dt id="src.engine.models.transformer.TransformerEstimator.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, dataset: datasets.dataset_dict.DatasetDict) ‑> float</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper of fit method.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dataset</code></strong> :&ensp;<code>DatasetDict</code></dt>
<dd>A dictionary containing training and validation sets.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>best_val_acc</code></strong> :&ensp;<code>float</code></dt>
<dd>Best obtained validation accuracy for all epochs until early stopping or end.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, dataset: DatasetDict) -&gt; float:
    &#34;&#34;&#34;Wrapper of fit method.

    Parameters
    ----------
    dataset : `DatasetDict`
        A dictionary containing training and validation sets.

    Returns
    -------
    best_val_acc : float
        Best obtained validation accuracy for all epochs until early stopping or end.
    &#34;&#34;&#34;
    # Get parameters
    batch_size = self.model_params.get(&#34;batch_size&#34;, 12)
    epochs = self.model_params.get(&#34;epochs&#34;, 20)
    verbose = self.model_params.get(&#34;verbose&#34;, 1)
    patience = self.model_params.get(&#34;patience&#34;, 2)

    # Apply transforms on the fly
    transforms = self.create_transform()

    dataset.set_transform(partial(apply_transform, transforms))

    train_set = dataset[&#34;train&#34;]
    val_set = dataset[&#34;validation&#34;]

    # Load dataset
    train_loader = DataLoader(
        train_set, batch_size=batch_size, collate_fn=collate_fn, shuffle=True, num_workers=1
    )
    val_loader = DataLoader(
        val_set, batch_size=batch_size, collate_fn=collate_fn, shuffle=False, num_workers=1
    )

    n_train = len(train_loader.dataset)
    n_train_batches = len(train_loader)

    n_val = len(val_loader.dataset)
    n_val_batches = len(val_loader)

    # Initialize optimizer and learning rate scheduler
    optimizer = self.create_optimizer()

    n_train_steps = epochs * n_train_batches
    lr_scheduler = get_scheduler(
        name=&#34;linear&#34;, optimizer=optimizer, num_warmup_steps=0,
        num_training_steps=n_train_steps
    )

    # Start training
    use_cuda = True
    log_interval = 1

    val_loss_list = []
    val_acc_list = []

    for epoch in range(epochs):

        # Training
        self.model.train()

        train_loss = 0
        train_correct = 0

        for batch_idx, batch in enumerate(train_loader):

            if use_cuda:
                batch = {k: v.cuda() for k, v in batch.items()}

            data = batch[&#34;pixel_values&#34;]
            target = batch[&#34;labels&#34;]

            # Set optimizer to zero grad
            optimizer.zero_grad()

            # Forward pass
            output = self.model(**batch).logits

            criterion = CrossEntropyLoss(reduction=&#34;mean&#34;)
            loss = criterion(output, target)

            # Backward pass
            loss.backward()

            optimizer.step()
            lr_scheduler.step()

            # Compute metrics and eventually print
            if verbose &gt; 0 and batch_idx % log_interval == 0:

                n_cur = batch_idx * len(data)
                perc_cur = 100. * batch_idx / n_train_batches
                log_msg = f&#34;[{n_cur}/{n_train} ({perc_cur:.0f}%)]&#34;

                batch_loss = loss.data.item()
                log_msg += f&#34;\tBatch loss: {batch_loss:.3f}&#34;

                pred = output.data.max(1, keepdim=True)[1]
                correct = pred.eq(target.data.view_as(pred)).cpu().sum()
                batch_acc = 100. * correct / len(data)
                log_msg += f&#34;\tBatch acc: {batch_acc:.2f}&#34;

                print(log_msg)

                train_loss += batch_loss  # total loss for epoch
                train_correct += correct  # total number of correct predictions for epoch

        train_loss /= n_train_batches
        train_acc = 100. * train_correct / n_train

        log_msg = f&#34;\nEpoch {epoch}; Training set: &#34;
        log_msg += f&#34;Average loss: {train_loss:.4f}; &#34;
        log_msg += f&#34;Accuracy: {train_correct}/{n_train} ({train_acc:.2f}%)&#34;
        print(log_msg)

        # Validation
        self.model.eval()

        val_loss = 0
        val_correct = 0

        for batch in val_loader:

            if use_cuda:
                batch = {k: v.cuda() for k, v in batch.items()}

            data = batch[&#34;pixel_values&#34;]
            target = batch[&#34;labels&#34;]

            # Forward pass
            output = self.model(**batch).logits

            criterion = CrossEntropyLoss(reduction=&#34;mean&#34;)
            val_loss += criterion(output, target).data.item()

            pred = output.data.max(1, keepdim=True)[1]
            val_correct += pred.eq(target.data.view_as(pred)).cpu().sum()

        val_loss /= n_val_batches
        val_acc = 100. * val_correct / n_val

        log_msg = &#34;Validation set: &#34;
        log_msg += f&#34;Average loss: {val_loss:.4f}; &#34;
        log_msg += f&#34;Accuracy: {val_correct}/{n_val} ({val_acc:.2f}%)\n&#34;
        print(log_msg)

        val_loss_list.append(val_loss)
        val_acc_list.append(val_acc)

        # Early stopping
        if len(val_acc_list) &gt; patience:

            worse_acc = True
            for past_acc in val_acc_list[-1-patience:-1]:
                if val_acc_list[-1] &gt; past_acc:
                    worse_acc = False

            if worse_acc:

                log_msg = &#34;Early stopping - patience&#34;
                print(log_msg)

                best_val_acc = np.max(val_acc_list)

                return best_val_acc

        if val_acc &lt; 10:

            log_msg = &#34;Early stopping - very bad model&#34;
            print(log_msg)

            best_val_acc = np.max(val_acc_list)

            return best_val_acc

    model_file = f&#34;experiment/{self.model_name}_{str(epoch)}.pth&#34;
    torch.save(self.model.state_dict(), model_file)

    log_msg = f&#34;Saved model to {model_file}\n&#34;
    print(log_msg)

    best_val_acc = np.max(val_acc_list)

    return best_val_acc</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.engine.models" href="index.html">src.engine.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="src.engine.models.transformer.TransformerEstimator" href="#src.engine.models.transformer.TransformerEstimator">TransformerEstimator</a></code></h4>
<ul class="">
<li><code><a title="src.engine.models.transformer.TransformerEstimator.create_optimizer" href="#src.engine.models.transformer.TransformerEstimator.create_optimizer">create_optimizer</a></code></li>
<li><code><a title="src.engine.models.transformer.TransformerEstimator.create_transform" href="#src.engine.models.transformer.TransformerEstimator.create_transform">create_transform</a></code></li>
<li><code><a title="src.engine.models.transformer.TransformerEstimator.fit" href="#src.engine.models.transformer.TransformerEstimator.fit">fit</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>